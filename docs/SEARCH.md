# Search Services Documentation

## Overview

nself provides integrated support for 6 different search engines, all fully self-hosted. Each engine offers different features and performance characteristics to match your specific needs.

## Supported Search Engines

### 1. Meilisearch (Default)
**Best for**: General purpose search with typo tolerance
- **Port**: 7700
- **Dashboard**: http://localhost:7700
- **Features**: 
  - Lightning fast search
  - Typo tolerance
  - Faceted search
  - Multi-language support
  - Built-in dashboard
- **Resource Usage**: Medium (500MB-2GB RAM)
- **Use Case**: E-commerce, documentation, general search

### 2. Typesense
**Best for**: Real-time search with instant results
- **Port**: 8108
- **API**: http://localhost:8108
- **Features**:
  - Blazing fast search (<50ms)
  - Typo tolerance
  - Faceted search
  - Geo search
  - Vector search
- **Resource Usage**: Low-Medium (200MB-1GB RAM)
- **Use Case**: Instant search, autocomplete, e-commerce

### 3. Zinc
**Best for**: Lightweight Elasticsearch alternative
- **Port**: 4080
- **Dashboard**: http://localhost:4080
- **Features**:
  - Elasticsearch compatible API
  - Full-text search
  - Aggregations
  - Built-in UI
  - Single binary
- **Resource Usage**: Very Low (100MB-500MB RAM)
- **Use Case**: Logs, simple search, resource-constrained environments

### 4. Elasticsearch
**Best for**: Enterprise search and analytics
- **Port**: 9200
- **API**: http://localhost:9200
- **Features**:
  - Industry standard
  - Full-text search
  - Complex aggregations
  - Machine learning
  - Extensive plugin ecosystem
- **Resource Usage**: High (2GB-8GB RAM minimum)
- **Use Case**: Large-scale search, log analysis, analytics

### 5. OpenSearch
**Best for**: Open-source Elasticsearch alternative
- **Port**: 9200
- **Dashboard Port**: 5601
- **API**: http://localhost:9200
- **Dashboard**: http://localhost:5601
- **Features**:
  - Elasticsearch fork
  - Security features
  - Alerting
  - Anomaly detection
  - SQL support
- **Resource Usage**: High (2GB-8GB RAM minimum)
- **Use Case**: Enterprise search with advanced security needs

### 6. Sonic
**Best for**: Ultra-lightweight search
- **Port**: 1491
- **API**: TCP protocol
- **Features**:
  - Minimal resource usage
  - Schema-less
  - Fast indexing
  - Auto-complete
  - Simple API
- **Resource Usage**: Extremely Low (30MB-100MB RAM)
- **Use Case**: Simple search, embedded systems, microservices

## Configuration

### Basic Setup

1. **Enable search in your `.env` file**:
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=meilisearch  # or typesense, zinc, elasticsearch, opensearch, sonic
```

2. **Build and start**:
```bash
nself build
nself start
```

### Engine-Specific Configuration

#### Meilisearch
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=meilisearch
MEILISEARCH_PORT=7700
MEILISEARCH_MASTER_KEY=<auto-generated>
```

#### Typesense
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=typesense
TYPESENSE_PORT=8108
TYPESENSE_API_KEY=<auto-generated>
```

#### Zinc
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=zinc
ZINC_PORT=4080
ZINC_ADMIN_USER=admin
ZINC_ADMIN_PASSWORD=<auto-generated>
```

#### Elasticsearch
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=elasticsearch
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_DISCOVERY_TYPE=single-node
```

#### OpenSearch
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=opensearch
OPENSEARCH_PORT=9200
OPENSEARCH_DASHBOARD_PORT=5601
OPENSEARCH_INITIAL_ADMIN_PASSWORD=<auto-generated>
```

#### Sonic
```bash
SEARCH_ENABLED=true
SEARCH_ENGINE=sonic
SONIC_PORT=1491
SONIC_PASSWORD=<auto-generated>
```

## Using the Search Command

### Check search status
```bash
nself search status
```

### Reindex data
```bash
nself search reindex
```

### View search logs
```bash
nself logs search
```

### Access search dashboard (if available)
```bash
nself search dashboard
```

## Integration with Hasura

Each search engine can be integrated with Hasura for GraphQL queries:

### 1. Add Remote Schema
```graphql
# For Meilisearch
http://meilisearch:7700/graphql

# For Typesense
http://typesense:8108/graphql

# For Elasticsearch
http://elasticsearch:9200/graphql
```

### 2. Create Search Action
```graphql
type Query {
  search(
    query: String!
    index: String!
    limit: Int
    offset: Int
  ): SearchResult
}

type SearchResult {
  hits: [Hit]
  total: Int
  processingTime: Int
}

type Hit {
  id: String
  score: Float
  document: JSON
}
```

## Client SDKs

### JavaScript/TypeScript

#### Meilisearch
```bash
npm install meilisearch
```

```javascript
import { MeiliSearch } from 'meilisearch'

const client = new MeiliSearch({
  host: 'http://localhost:7700',
  apiKey: process.env.MEILISEARCH_MASTER_KEY,
})

// Search
const results = await client.index('products').search('laptop', {
  limit: 10,
  attributesToHighlight: ['name', 'description']
})
```

#### Typesense
```bash
npm install typesense
```

```javascript
import Typesense from 'typesense'

const client = new Typesense.Client({
  nodes: [{
    host: 'localhost',
    port: '8108',
    protocol: 'http'
  }],
  apiKey: process.env.TYPESENSE_API_KEY,
})

// Search
const results = await client.collections('products')
  .documents()
  .search({
    q: 'laptop',
    query_by: 'name,description'
  })
```

#### Elasticsearch
```bash
npm install @elastic/elasticsearch
```

```javascript
import { Client } from '@elastic/elasticsearch'

const client = new Client({
  node: 'http://localhost:9200'
})

// Search
const result = await client.search({
  index: 'products',
  body: {
    query: {
      match: { name: 'laptop' }
    }
  }
})
```

### Python

#### Meilisearch
```bash
pip install meilisearch
```

```python
import meilisearch

client = meilisearch.Client(
    'http://localhost:7700',
    os.environ['MEILISEARCH_MASTER_KEY']
)

# Search
results = client.index('products').search('laptop', {
    'limit': 10,
    'attributesToHighlight': ['name', 'description']
})
```

## Indexing Data

### From PostgreSQL

Use Hasura's event triggers to sync data:

```sql
-- Create trigger function
CREATE OR REPLACE FUNCTION sync_to_search()
RETURNS trigger AS $$
BEGIN
  -- Send to search service via webhook
  PERFORM pg_notify('search_sync', row_to_json(NEW)::text);
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create trigger
CREATE TRIGGER products_search_sync
AFTER INSERT OR UPDATE OR DELETE ON products
FOR EACH ROW EXECUTE FUNCTION sync_to_search();
```

### Batch Import

```bash
# Import from CSV
nself search import --index=products --file=products.csv

# Import from JSON
nself search import --index=products --file=products.json

# Import from PostgreSQL
nself search sync --table=products --index=products
```

## Performance Comparison

| Engine | Index Speed | Search Speed | RAM Usage | Disk Usage | Best For |
|--------|------------|--------------|-----------|------------|----------|
| Meilisearch | Fast | Very Fast | Medium | Medium | General purpose |
| Typesense | Very Fast | Extremely Fast | Low | Low | Real-time search |
| Zinc | Fast | Fast | Very Low | Low | Simple search |
| Elasticsearch | Medium | Fast | High | High | Complex queries |
| OpenSearch | Medium | Fast | High | High | Enterprise |
| Sonic | Extremely Fast | Very Fast | Minimal | Minimal | Embedded |

## Choosing the Right Engine

### Choose Meilisearch if you need:
- Typo tolerance out of the box
- Multi-language support
- Beautiful built-in dashboard
- Good balance of features and resources

### Choose Typesense if you need:
- Instant search (sub-50ms)
- Vector search capabilities
- Geo-location search
- Best autocomplete experience

### Choose Zinc if you need:
- Elasticsearch-compatible API
- Minimal resource usage
- Single binary deployment
- Log search capabilities

### Choose Elasticsearch if you need:
- Industry standard compatibility
- Complex aggregations
- Machine learning features
- Extensive plugin ecosystem

### Choose OpenSearch if you need:
- Elasticsearch features with open license
- Advanced security features
- Built-in alerting
- AWS compatibility

### Choose Sonic if you need:
- Absolute minimal resource usage
- Simple schema-less indexing
- Embedded search capability
- Microservice architecture

## Troubleshooting

### Search service not starting
```bash
# Check logs
nself logs search

# Verify configuration
nself doctor

# Check port availability
lsof -i :7700  # Or relevant port
```

### Indexing issues
```bash
# Clear index
nself search clear --index=products

# Rebuild index
nself search reindex --index=products

# Check index status
nself search status --index=products
```

### Performance issues
```bash
# Check resource usage
docker stats ${PROJECT_NAME}_search

# Increase memory limits
# Edit docker-compose.yml
services:
  search:
    deploy:
      resources:
        limits:
          memory: 2G
```

## Security Considerations

### API Keys
All search engines are configured with secure API keys:
- Keys are auto-generated during `nself build`
- Stored in `.env` file
- Never commit keys to version control

### Network Security
- Search services are not exposed externally by default
- Access through nginx proxy with authentication
- Use `SEARCH_EXTERNAL_ACCESS=false` to restrict access

### Data Security
- Enable encryption at rest where supported
- Use volume encryption for sensitive data
- Regular backups with `nself backup`

## Monitoring

### Health Checks
```bash
# Check search health
nself search health

# Monitor with nself
nself monitor search
```

### Metrics
Available metrics via Prometheus (when monitoring enabled):
- Index size
- Query latency
- Document count
- Error rate
- Resource usage

## Migration Guide

### From External Search Service

1. **Export data from external service**
2. **Choose appropriate engine** based on features needed
3. **Configure in `.env`**:
   ```bash
   SEARCH_ENABLED=true
   SEARCH_ENGINE=meilisearch
   ```
4. **Build and start**:
   ```bash
   nself build
   nself start
   ```
5. **Import data**:
   ```bash
   nself search import --file=exported-data.json
   ```
6. **Update application configuration** to use local endpoint

### Between Search Engines

To switch between search engines:

1. **Backup current data**:
   ```bash
   nself search export --output=search-backup.json
   ```

2. **Update configuration**:
   ```bash
   # Edit .env
   SEARCH_ENGINE=typesense  # New engine
   ```

3. **Rebuild**:
   ```bash
   nself build --force
   nself restart search
   ```

4. **Import data**:
   ```bash
   nself search import --file=search-backup.json
   ```

## Advanced Configuration

### Multi-node Clustering (Elasticsearch/OpenSearch)

```yaml
# docker-compose.override.yml
services:
  elasticsearch:
    environment:
      - cluster.name=nself-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - cluster.name=nself-cluster
      - discovery.seed_hosts=elasticsearch,es03
      
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - cluster.name=nself-cluster
      - discovery.seed_hosts=elasticsearch,es02
```

### Custom Analyzers (Meilisearch)

```javascript
// Configure custom settings
await client.index('products').updateSettings({
  searchableAttributes: ['name', 'description', 'tags'],
  filterableAttributes: ['price', 'category'],
  sortableAttributes: ['price', 'created_at'],
  synonyms: {
    'laptop': ['notebook', 'computer'],
    'phone': ['mobile', 'smartphone']
  },
  stopWords: ['the', 'a', 'an'],
  rankingRules: [
    'words',
    'typo',
    'proximity',
    'attribute',
    'sort',
    'exactness'
  ]
})
```

## API Examples

### REST API

#### Meilisearch
```bash
# Search
curl -X POST 'http://localhost:7700/indexes/products/search' \
  -H 'Authorization: Bearer YOUR_MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "q": "laptop",
    "limit": 10
  }'

# Add document
curl -X POST 'http://localhost:7700/indexes/products/documents' \
  -H 'Authorization: Bearer YOUR_MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '[
    {
      "id": 1,
      "name": "MacBook Pro",
      "price": 1299
    }
  ]'
```

#### Typesense
```bash
# Search
curl -X GET 'http://localhost:8108/collections/products/documents/search' \
  -H "X-TYPESENSE-API-KEY: YOUR_API_KEY" \
  --data-urlencode "q=laptop" \
  --data-urlencode "query_by=name,description"
```

### GraphQL (via Hasura)

```graphql
query SearchProducts {
  search_products(
    args: {
      query: "laptop",
      limit: 10,
      offset: 0
    }
  ) {
    id
    name
    description
    price
    score
  }
}
```

## Best Practices

1. **Index only what you search**: Don't index unnecessary fields
2. **Use appropriate field types**: Text for search, keyword for filtering
3. **Implement pagination**: Use limit/offset for large result sets
4. **Cache frequent queries**: Use Redis for common searches
5. **Monitor performance**: Track query times and optimize slow queries
6. **Regular maintenance**: Reindex periodically for optimal performance
7. **Backup indexes**: Include in your backup strategy
8. **Use bulk operations**: For better indexing performance
9. **Implement retry logic**: Handle temporary failures gracefully
10. **Security first**: Always use API keys and HTTPS in production

## Related Documentation

- [COMMANDS.md](./COMMANDS.md) - Search command reference
- [CONFIGURATION.md](./CONFIG.md) - Configuration options
- [API.md](./API.md) - API integration guide
- [TROUBLESHOOTING.md](./TROUBLESHOOTING.md) - Common issues and solutions
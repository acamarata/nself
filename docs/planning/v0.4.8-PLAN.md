# v0.4.8 Planning - Kubernetes Support

**Target**: Q3-Q4 2026
**Focus**: Container orchestration at scale

**Depends on**: v0.4.7 (cloud providers for managed Kubernetes)

---

## Overview

Full Kubernetes support including manifest generation from docker-compose, Helm chart packaging, and integration with major managed Kubernetes services (EKS, GKE, AKS, DOKS, LKE).

---

## New Commands

| Command | Purpose |
|---------|---------|
| `nself k8s` | Kubernetes operations |
| `nself helm` | Helm chart management |

---

## Supported Platforms

| Platform | Provider | Status |
|----------|----------|--------|
| **EKS** | AWS | Full |
| **GKE** | Google Cloud | Full |
| **AKS** | Azure | Full |
| **DOKS** | DigitalOcean | Full |
| **LKE** | Linode | Full |
| **Self-Hosted** | Any | Full |
| **k3s** | Edge/IoT | Full |
| **minikube** | Local Dev | Full |

---

## Detailed Feature Specifications

### 1. Kubernetes Operations (`nself k8s`)

#### Subcommands
```bash
# Generation
nself k8s generate               # Generate K8s manifests from compose
nself k8s generate --output ./k8s
nself k8s generate --namespace myapp

# Deployment
nself k8s apply                  # Apply manifests to cluster
nself k8s apply --env staging    # Apply to specific context
nself k8s apply --dry-run        # Preview changes

# Status
nself k8s status                 # Cluster status
nself k8s status <service>       # Service status
nself k8s pods                   # List all pods
nself k8s events                 # Recent events

# Operations
nself k8s logs <service>         # Pod logs
nself k8s logs <service> -f      # Follow logs
nself k8s exec <service>         # Exec into pod
nself k8s shell <service>        # Interactive shell

# Rollout
nself k8s rollout <service>      # Rolling update
nself k8s rollout status         # Rollout status
nself k8s rollback <service>     # Rollback deployment
nself k8s rollback --to v1.2.3   # Rollback to version

# Scaling
nself k8s scale <service> 3      # Scale to 3 replicas
nself k8s autoscale <service>    # Enable HPA

# Cluster management
nself k8s context                # Show current context
nself k8s context use <name>     # Switch context
nself k8s contexts               # List all contexts
```

#### Manifest Generation

From docker-compose.yml to Kubernetes manifests:

```bash
nself k8s generate

# Creates:
k8s/
├── namespace.yaml
├── configmaps/
│   ├── app-config.yaml
│   └── nginx-config.yaml
├── secrets/
│   └── app-secrets.yaml
├── deployments/
│   ├── postgres.yaml
│   ├── hasura.yaml
│   ├── auth.yaml
│   ├── api.yaml
│   └── nginx.yaml
├── services/
│   ├── postgres-service.yaml
│   ├── hasura-service.yaml
│   └── ...
├── ingress/
│   └── ingress.yaml
├── volumes/
│   └── persistent-volumes.yaml
└── kustomization.yaml
```

##### Generated Deployment Example

```yaml
# k8s/deployments/api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
  namespace: myapp
  labels:
    app: api
    version: v1.0.0
spec:
  replicas: 2
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
        - name: api
          image: myapp/api:latest
          ports:
            - containerPort: 8080
          envFrom:
            - configMapRef:
                name: app-config
            - secretRef:
                name: app-secrets
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            periodSeconds: 20
```

#### Ingress Configuration

```yaml
# k8s/ingress/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: myapp
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
    - hosts:
        - myapp.com
        - api.myapp.com
        - admin.myapp.com
      secretName: myapp-tls
  rules:
    - host: myapp.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: nginx
                port:
                  number: 80
    - host: api.myapp.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: hasura
                port:
                  number: 8080
```

#### Kustomize Support

```yaml
# k8s/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: myapp

resources:
  - namespace.yaml
  - configmaps/
  - secrets/
  - deployments/
  - services/
  - ingress/
  - volumes/

images:
  - name: myapp/api
    newTag: v1.0.0

replicas:
  - name: api
    count: 2
```

#### Environment-Specific Overlays

```
k8s/
├── base/
│   └── ... (generated manifests)
├── overlays/
│   ├── local/
│   │   ├── kustomization.yaml
│   │   └── patches/
│   ├── staging/
│   │   ├── kustomization.yaml
│   │   └── patches/
│   └── production/
│       ├── kustomization.yaml
│       └── patches/
```

---

### 2. Helm Chart Management (`nself helm`)

#### Subcommands
```bash
# Chart creation
nself helm init                  # Initialize Helm chart
nself helm init --from-compose   # Generate from docker-compose

# Packaging
nself helm package               # Package chart
nself helm lint                  # Lint chart
nself helm template              # Render templates locally

# Installation
nself helm install               # Install to cluster
nself helm install --env staging # Environment-specific values
nself helm upgrade               # Upgrade release
nself helm rollback              # Rollback release

# Management
nself helm list                  # List releases
nself helm status                # Release status
nself helm history               # Release history
nself helm uninstall             # Remove release

# Repository
nself helm repo add <url>        # Add chart repo
nself helm push                  # Push to registry
```

#### Generated Helm Chart Structure

```bash
nself helm init

# Creates:
helm/myapp/
├── Chart.yaml
├── values.yaml
├── values-staging.yaml
├── values-production.yaml
├── templates/
│   ├── _helpers.tpl
│   ├── namespace.yaml
│   ├── configmap.yaml
│   ├── secret.yaml
│   ├── deployment.yaml
│   ├── service.yaml
│   ├── ingress.yaml
│   ├── pvc.yaml
│   ├── hpa.yaml
│   └── NOTES.txt
└── charts/
    ├── postgresql/
    └── redis/
```

##### Chart.yaml

```yaml
apiVersion: v2
name: myapp
description: A Helm chart for myapp
type: application
version: 1.0.0
appVersion: "1.0.0"

dependencies:
  - name: postgresql
    version: "12.x.x"
    repository: https://charts.bitnami.com/bitnami
    condition: postgresql.enabled
  - name: redis
    version: "17.x.x"
    repository: https://charts.bitnami.com/bitnami
    condition: redis.enabled
```

##### values.yaml

```yaml
# Default values for myapp

replicaCount: 1

image:
  repository: myapp/api
  pullPolicy: IfNotPresent
  tag: ""  # Defaults to chart appVersion

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: myapp.local
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: myapp-tls
      hosts:
        - myapp.local

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80

postgresql:
  enabled: true
  auth:
    postgresPassword: ""  # Generated if empty
    database: myapp

redis:
  enabled: false
  auth:
    password: ""
```

##### values-production.yaml

```yaml
# Production overrides

replicaCount: 3

resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 500m
    memory: 512Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70

ingress:
  hosts:
    - host: myapp.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: myapp-prod-tls
      hosts:
        - myapp.com

postgresql:
  primary:
    persistence:
      size: 100Gi
    resources:
      limits:
        memory: 4Gi
        cpu: 2
```

---

### 3. Additional Orchestration Support

#### Docker Swarm

```bash
nself swarm init                 # Initialize Swarm mode
nself swarm deploy               # Deploy stack
nself swarm status               # Stack status
nself swarm scale <service> 3    # Scale service
```

#### Nomad

```bash
nself nomad generate             # Generate Nomad job specs
nself nomad run                  # Run jobs
nself nomad status               # Job status
```

#### Service Mesh Integration

```bash
# Istio
nself k8s mesh enable istio      # Enable Istio sidecar injection
nself k8s mesh traffic           # Traffic management
nself k8s mesh mtls              # Enable mTLS

# Linkerd
nself k8s mesh enable linkerd
```

---

## Implementation Files

### New CLI Commands
```
src/cli/k8s.sh               # Kubernetes operations
src/cli/helm.sh              # Helm chart management
src/cli/swarm.sh             # Docker Swarm (optional)
src/cli/nomad.sh             # Nomad (optional)
```

### New Library Files
```
src/lib/k8s/
├── generate.sh              # Manifest generation
├── apply.sh                 # Deployment
├── status.sh                # Status monitoring
├── logs.sh                  # Log streaming
├── exec.sh                  # Pod exec
├── rollout.sh               # Rolling updates
├── scale.sh                 # Scaling
├── context.sh               # Context management
└── convert/
    ├── compose-to-k8s.sh    # Compose conversion
    └── compose-to-helm.sh   # Helm conversion

src/lib/helm/
├── init.sh                  # Chart initialization
├── package.sh               # Packaging
├── install.sh               # Installation
├── upgrade.sh               # Upgrades
├── rollback.sh              # Rollbacks
└── repo.sh                  # Repository management

src/lib/orchestration/
├── swarm.sh                 # Docker Swarm
├── nomad.sh                 # HashiCorp Nomad
└── mesh/
    ├── istio.sh             # Istio integration
    └── linkerd.sh           # Linkerd integration
```

### Templates
```
src/templates/k8s/
├── deployment.yaml.template
├── service.yaml.template
├── ingress.yaml.template
├── configmap.yaml.template
├── secret.yaml.template
├── pvc.yaml.template
├── hpa.yaml.template
└── kustomization.yaml.template

src/templates/helm/
├── Chart.yaml.template
├── values.yaml.template
├── _helpers.tpl.template
└── NOTES.txt.template
```

---

## Environment Variable Additions

```bash
# Kubernetes
K8S_NAMESPACE=default
K8S_CONTEXT=
K8S_CONFIG=~/.kube/config

# Helm
HELM_RELEASE_NAME=myapp
HELM_CHART_VERSION=1.0.0
HELM_REPOSITORY=

# Ingress
K8S_INGRESS_CLASS=nginx
K8S_INGRESS_ANNOTATIONS=

# Service Mesh
K8S_SERVICE_MESH=none  # none, istio, linkerd
```

---

## Dependencies

- `kubectl` (Kubernetes CLI)
- `helm` (Helm CLI)
- `kustomize` (optional, for overlays)
- `kompose` (optional, for compose conversion reference)

---

## Success Criteria

1. ✓ `nself k8s generate` creates valid K8s manifests
2. ✓ `nself k8s apply` deploys successfully to cluster
3. ✓ `nself helm init` creates functional Helm chart
4. ✓ `nself helm install` works with managed K8s (EKS, GKE, etc.)
5. ✓ Rolling updates work correctly
6. ✓ Ingress with TLS works out of the box
7. ✓ Horizontal Pod Autoscaler integrates properly

---

*Last Updated: January 22, 2026*
